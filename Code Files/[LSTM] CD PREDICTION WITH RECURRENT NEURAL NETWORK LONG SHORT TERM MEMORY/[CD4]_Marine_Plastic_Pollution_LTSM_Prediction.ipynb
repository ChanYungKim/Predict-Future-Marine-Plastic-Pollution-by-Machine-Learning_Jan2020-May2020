{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[CD4]_Marine_Plastic_Pollution_LTSM_Prediction","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"FU185J9Hqmfg","colab_type":"text"},"source":["CD1_(/km^2)\t0.335-0.999 mm\n","\n","CD2_(/km^2)\t1.00-4.75 mm\n","\n","CD3_(/km^2)\t4.75-200 mm\n","\n","CD4_(/km^2) >200 mm\n","\n","WD1_(g/km^2) 0.335-0.999 mm\n","\n","WD2_(g/km^2) 1.00-4.75 mm\n","\n","WD3_(g/km^2) 4.75-200 mm\n","\t\t\n","WD4_(g/km^2) >200 mm\t\t\t"]},{"cell_type":"code","metadata":{"id":"X7IXVn8PgwY8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"b65ede7e-86a9-40da-880e-eaf63b5f7328","executionInfo":{"status":"ok","timestamp":1589159803577,"user_tz":-540,"elapsed":2582,"user":{"displayName":"Chan Yung Kim","photoUrl":"","userId":"08860047164087785383"}}},"source":["import math\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"3VAXz6icXfR9","colab_type":"text"},"source":["**PREPROCESSING DATA**"]},{"cell_type":"code","metadata":{"id":"O5t9C2BcZA_G","colab_type":"code","colab":{}},"source":["import pandas as pd\n","\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive/')\n","pollution_data = pd.read_csv('/content/gdrive/My Drive/AI_NoteBook/PROJECT/Import_File/PlasticMarinePollutionDataset.csv')\n","\n","########## [PREPROCESSING] ##########\n","pollution_data.rename(columns = {'CD1_(/km^2)' : 'Count_Density_Class1Plastic'}, inplace = True)\n","pollution_data.rename(columns = {'CD2_(/km^2)' : 'Count_Density_Class2Plastic'}, inplace = True)\n","pollution_data.rename(columns = {'CD3_(/km^2)' : 'Count_Density_Class3Plastic'}, inplace = True)\n","pollution_data.rename(columns = {'CD4 _(/km^2)' : 'Count_Density_Class4Plastic'}, inplace = True)\n","\n","pollution_data.rename(columns = {'WD1_(g/km^2)' : 'Weight_Density_Class1Plastic'}, inplace = True)\n","pollution_data.rename(columns = {'WD2_(g/km^2)' : 'Weight_Density_Class2Plastic'}, inplace = True)\n","pollution_data.rename(columns = {'WD3_(g/km^2)' : 'Weight_Density_Class3Plastic'}, inplace = True)\n","pollution_data.rename(columns = {'WD4_(g/km^2)' : 'Weight_Density_Class4Plastic'}, inplace = True)\n","\n","pollution_data['Count_Density_Class1Plastic'] = pollution_data.Count_Density_Class1Plastic.str.replace(' ', '')\n","pollution_data['Count_Density_Class2Plastic'] = pollution_data.Count_Density_Class2Plastic.str.replace(' ', '')\n","pollution_data['Count_Density_Class3Plastic'] = pollution_data.Count_Density_Class3Plastic.str.replace(' ', '')\n","pollution_data['Weight_Density_Class2Plastic'] = pollution_data.Weight_Density_Class2Plastic.str.replace(' ', '')\n","pollution_data['Weight_Density_Class3Plastic'] = pollution_data.Weight_Density_Class3Plastic.str.replace(' ', '')\n","pollution_data['Weight_Density_Class4Plastic'] = pollution_data.Weight_Density_Class4Plastic.str.replace(' ', '')\n","\n","pollution_data['Count_Density_Class1Plastic'] = pollution_data.Count_Density_Class1Plastic.str.replace(',', '').astype(float)\n","pollution_data['Count_Density_Class2Plastic'] = pollution_data.Count_Density_Class2Plastic.str.replace(',', '').astype(float)\n","pollution_data['Count_Density_Class3Plastic'] = pollution_data.Count_Density_Class3Plastic.str.replace(',', '').astype(float)\n","pollution_data['Weight_Density_Class2Plastic'] = pollution_data.Weight_Density_Class2Plastic.str.replace(',', '').astype(float)\n","pollution_data['Weight_Density_Class3Plastic'] = pollution_data.Weight_Density_Class3Plastic.str.replace(',', '').astype(float)\n","pollution_data['Weight_Density_Class4Plastic'] = pollution_data.Weight_Density_Class4Plastic.str.replace(',', '').astype(float)\n","\n","pollution_data = pollution_data.drop_duplicates(keep = 'first')\n","\n","pollution_data['Data'] = pollution_data.Date.astype(str)\n","\n","pollution_data_4 = pollution_data[['Date','Count_Density_Class4Plastic']]\n","\n","pollution_data_4 = pollution_data_4.dropna(how = 'any')\n","\n","########## [REMOVE ZEROS] #########\n","pollution_data_4 = pollution_data_4.drop(index = pollution_data_4[pollution_data_4['Count_Density_Class4Plastic'] == 0].index)\n","###################################\n","\n","pollution_data_4['Date'] = pd.to_datetime(pollution_data_4.Date)\n","\n","pollution_data_4_GroupByDate = pollution_data_4.groupby('Date').Count_Density_Class4Plastic.sum()\n","\n","pollution_data_4_GroupByDate = pd.DataFrame(pollution_data_4_GroupByDate)\n","\n","pollution_data_4_GroupByDate ['Date'] = pollution_data_4_GroupByDate.index\n","\n","######### [MOVING AVERAGES APPROACH FOR PLASTIC] ##########\n","pollution_data_4_GroupByDate ['Plastic_Moving_Average_9'] = pollution_data_4_GroupByDate.Count_Density_Class4Plastic.rolling(9, center=True).mean()\n","pollution_data_4_GroupByDate ['Plastic_Moving_Average_21'] = pollution_data_4_GroupByDate.Count_Density_Class4Plastic.rolling(21, center=True).mean()\n","pollution_data_4_GroupByDate ['Plastic_Moving_Average_36'] = pollution_data_4_GroupByDate.Count_Density_Class4Plastic.rolling(36, center=True).mean()\n","###########################################################\n","\n","startdate = pd.to_datetime('2008/02/06')\n","\n","pollution_data_4_GroupByDate ['Days after 2008-02-06'] = (pollution_data_4_GroupByDate.Date).subtract(startdate)\n","\n","pollution_data_4_GroupByDate ['Days after 2008-02-06']  = pollution_data_4_GroupByDate['Days after 2008-02-06'].astype(str)\n","\n","pollution_data_4_GroupByDate ['Days after 2008-02-06'] = pollution_data_4_GroupByDate ['Days after 2008-02-06'].str.replace(' days 00:00:00.000000000', '')\n","pollution_data_4_GroupByDate ['Days after 2008-02-06'] = pollution_data_4_GroupByDate ['Days after 2008-02-06'].astype(float)\n","\n","######### [MOVING AVERAGES APPROACH FOR Days] ##########\n","pollution_data_4_GroupByDate ['Days_Moving_Average_9'] = pollution_data_4_GroupByDate ['Days after 2008-02-06'].rolling(9, center=True).mean()\n","pollution_data_4_GroupByDate ['Days_Moving_Average_21'] = pollution_data_4_GroupByDate ['Days after 2008-02-06'].rolling(21, center=True).mean()\n","pollution_data_4_GroupByDate ['Days_Moving_Average_36'] = pollution_data_4_GroupByDate ['Days after 2008-02-06'].rolling(36, center=True).mean()\n","###########################################################\n","print (pollution_data_4_GroupByDate.head(-5))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GZM-YUfQyYeb","colab_type":"code","colab":{}},"source":["Dataset_1 = pollution_data_4_GroupByDate.filter(['Count_Density_Class4Plastic'])\n","\n","Dataset_2 = pollution_data_4_GroupByDate.filter(['Plastic_Moving_Average_9'])\n","Dataset_2 = Dataset_2.dropna(how='any')\n","\n","Dataset_3 = pollution_data_4_GroupByDate.filter(['Plastic_Moving_Average_21'])\n","Dataset_3 = Dataset_3.dropna(how='any')\n","\n","Dataset_4 = pollution_data_4_GroupByDate.filter(['Plastic_Moving_Average_36'])\n","Dataset_4 = Dataset_4.dropna(how='any')\n","\n","Dataset_1 = Dataset_1.to_numpy()\n","Dataset_2 = Dataset_2.to_numpy()\n","Dataset_3 = Dataset_3.to_numpy()\n","Dataset_4 = Dataset_4.to_numpy()\n","\n","training_data_length_1 = math.ceil (len(Dataset_1) * (0.8))\n","training_data_length_2 = math.ceil (len(Dataset_2) * (0.8))\n","training_data_length_3 = math.ceil (len(Dataset_3) * (0.8))\n","training_data_length_4 = math.ceil (len(Dataset_4) * (0.8))\n","\n","print (Dataset_1)\n","print (training_data_length_1)\n","print (training_data_length_2)\n","print (training_data_length_3)\n","print (training_data_length_4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E4LQRpIp0ZYP","colab_type":"code","colab":{}},"source":["scaler = MinMaxScaler(feature_range= (0,1))\n","\n","scaled_data_1 = scaler.fit_transform(Dataset_1)\n","scaled_data_2 = scaler.fit_transform(Dataset_2)\n","scaled_data_3 = scaler.fit_transform(Dataset_3)\n","scaled_data_4 = scaler.fit_transform(Dataset_4)\n","\n","print (scaled_data_1)\n","print (scaled_data_2)\n","print (scaled_data_3)\n","print (scaled_data_4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zWOtyGEU1udP","colab_type":"code","colab":{}},"source":["train_data_1 = scaled_data_1[0:training_data_length_1, :]\n","train_data_2 = scaled_data_1[0:training_data_length_2, :]\n","train_data_3 = scaled_data_1[0:training_data_length_3, :]\n","train_data_4 = scaled_data_1[0:training_data_length_4, :]\n","\n","X_train_1 = []\n","y_train_1 = []\n","\n","X_train_2 = []\n","y_train_2 = []\n","\n","X_train_3 = []\n","y_train_3 = []\n","\n","X_train_4 = []\n","y_train_4 = []\n","\n","for i in range (30, len (train_data_1)) :\n","  X_train_1.append(train_data_1[i-30:i, 0])\n","  y_train_1.append(train_data_1[i, 0])\n","\n","for i in range (30, len (train_data_2)) :\n","  X_train_2.append(train_data_2[i-30:i, 0])\n","  y_train_2.append(train_data_2[i, 0])\n","\n","for i in range (30, len (train_data_3)) :\n","  X_train_3.append(train_data_3[i-30:i, 0])\n","  y_train_3.append(train_data_3[i, 0])\n","\n","for i in range (30, len (train_data_4)) :\n","  X_train_4.append(train_data_4[i-30:i, 0])\n","  y_train_4.append(train_data_4[i, 0])\n","\n","X_train_1, y_train_1 = np.array(X_train_1), np.array(y_train_1)\n","X_train_2, y_train_2 = np.array(X_train_2), np.array(y_train_2)  \n","X_train_3, y_train_3 = np.array(X_train_3), np.array(y_train_3)  \n","X_train_4, y_train_4 = np.array(X_train_4), np.array(y_train_4)     "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DMfAL5qW4AJa","colab_type":"code","colab":{}},"source":["X_train_1 = np.reshape(X_train_1 ,(X_train_1.shape[0], X_train_1.shape[1], 1))\n","X_train_2 = np.reshape(X_train_2, (X_train_2.shape[0], X_train_2.shape[1], 1))\n","X_train_3 = np.reshape(X_train_3, (X_train_3.shape[0], X_train_3.shape[1], 1))\n","X_train_4 = np.reshape(X_train_4, (X_train_4.shape[0], X_train_4.shape[1], 1))\n","print (X_train_1.shape)\n","print (X_train_2.shape)\n","print (X_train_3.shape)\n","print (X_train_4.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WACxOIVb57dM","colab_type":"code","colab":{}},"source":["model = Sequential()\n","model.add(LSTM(50, return_sequences=True, input_shape = (X_train_1.shape[1], 1)))\n","model.add(LSTM(50, return_sequences=False))\n","model.add(Dense(25))\n","model.add(Dense(1))\n","\n","model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n","\n","model.fit(X_train_1, y_train_1, batch_size = 1, epochs = 3)\n","\n","test_data_1 = scaled_data_1[training_data_length_1 - 30:, :]\n","\n","X_test_1 = []\n","y_test_1 = Dataset_1[training_data_length_1:, :]\n","\n","for i in range(30, len(test_data_1)) :\n","  X_test_1.append(test_data_1[i-30: i, 0])\n","\n","X_test_1 = np.array(X_test_1)\n","\n","X_test_1 = np.reshape(X_test_1, (X_test_1.shape[0], X_test_1.shape[1], 1))\n","\n","Predictions = model.predict(X_test_1)\n","Predictions = scaler.inverse_transform(Predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hl_W3qbO_WcH","colab_type":"code","colab":{}},"source":["RMSE = np.sqrt(np.mean(Predictions - y_test_1)**2)\n","\n","RMSE"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6d8Shhbx_yuW","colab_type":"code","colab":{}},"source":["train = pollution_data_4_GroupByDate.filter(['Count_Density_Class4Plastic'])[:training_data_length_1]\n","valid = pollution_data_4_GroupByDate.filter(['Count_Density_Class4Plastic'])[training_data_length_1:]\n","valid ['Predictions'] = Predictions\n","\n","plt.figure(figsize=(16,8))\n","plt.title('Count Density', fontsize = 30)\n","plt.xlabel('Date', fontsize = 15, color = 'W')\n","plt.ylabel('Count Density per Unit Area', fontsize = 15, color = 'W')\n","plt.plot(train['Count_Density_Class4Plastic'], color = 'darkgray')\n","plt.plot(valid['Count_Density_Class4Plastic'], color = 'skyblue')\n","plt.plot(valid['Predictions'], color = 'blue')\n","plt.legend(['Train', 'Actual', 'Predictions'], loc = 'upper right')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cSFAltZauCzr","colab_type":"code","colab":{}},"source":["valid"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"drrKtF8kr_8F","colab_type":"code","colab":{}},"source":["model = Sequential()\n","model.add(LSTM(50, return_sequences=True, input_shape = (X_train_2.shape[1], 1)))\n","model.add(LSTM(50, return_sequences=False))\n","model.add(Dense(25))\n","model.add(Dense(1))\n","\n","model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n","\n","model.fit(X_train_2, y_train_2, batch_size = 1, epochs = 3)\n","\n","test_data_2 = scaled_data_2[training_data_length_2 - 30:, :]\n","\n","X_test_2 = []\n","y_test_2 = Dataset_2[training_data_length_2:, :]\n","\n","for i in range(30, len(test_data_2)) :\n","  X_test_2.append(test_data_2[i-30: i, 0])\n","\n","X_test_2 = np.array(X_test_2)\n","\n","X_test_2 = np.reshape(X_test_2, (X_test_2.shape[0], X_test_2.shape[1], 1))\n","\n","Predictions = model.predict(X_test_2)\n","Predictions = scaler.inverse_transform(Predictions)\n","\n","RMSE = np.sqrt(np.mean(Predictions - y_test_2)**2)\n","\n","RMSE"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PGz5dIjmQ8S0","colab_type":"code","colab":{}},"source":["train = pollution_data_4_GroupByDate.filter(['Plastic_Moving_Average_9']).dropna(how='any')[:training_data_length_2]\n","valid = pollution_data_4_GroupByDate.filter(['Plastic_Moving_Average_9']).dropna(how='any')[training_data_length_2:]\n","valid ['Predictions'] = Predictions\n","\n","plt.figure(figsize=(16,8))\n","plt.title('Count Density', fontsize = 30)\n","plt.xlabel('Date', fontsize = 15, color = 'W')\n","plt.ylabel('Count Density per Unit Area', fontsize = 15, color = 'W')\n","plt.plot(train['Plastic_Moving_Average_9'], color = 'darkgray')\n","plt.plot(valid['Plastic_Moving_Average_9'], color = 'skyblue')\n","plt.plot(valid['Predictions'], color = 'blue')\n","plt.legend(['Train', 'Actual', 'Predictions'], loc = 'upper right')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XijIlOgoSRmH","colab_type":"code","colab":{}},"source":["model = Sequential()\n","model.add(LSTM(50, return_sequences=True, input_shape = (X_train_3.shape[1], 1)))\n","model.add(LSTM(50, return_sequences=False))\n","model.add(Dense(25))\n","model.add(Dense(1))\n","\n","model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n","\n","model.fit(X_train_3, y_train_3, batch_size = 3, epochs = 3)\n","\n","test_data_3 = scaled_data_3[training_data_length_3 - 30:, :]\n","\n","X_test_3 = []\n","y_test_3 = Dataset_3[training_data_length_3:, :]\n","\n","for i in range(30, len(test_data_3)) :\n","  X_test_3.append(test_data_3[i-30: i, 0])\n","\n","X_test_3 = np.array(X_test_3)\n","\n","X_test_3 = np.reshape(X_test_3, (X_test_3.shape[0], X_test_3.shape[1], 1))\n","\n","Predictions = model.predict(X_test_3)\n","Predictions = scaler.inverse_transform(Predictions)\n","\n","RMSE = np.sqrt(np.mean(Predictions - y_test_3)**2)\n","\n","RMSE"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UkjuHCVpS9oe","colab_type":"code","colab":{}},"source":["train = pollution_data_4_GroupByDate.filter(['Plastic_Moving_Average_21']).dropna(how='any')[:training_data_length_3]\n","valid = pollution_data_4_GroupByDate.filter(['Plastic_Moving_Average_21']).dropna(how='any')[training_data_length_3:]\n","valid ['Predictions'] = Predictions\n","\n","plt.figure(figsize=(16,8))\n","plt.title('Count Density', fontsize = 30)\n","plt.xlabel('Date', fontsize = 15, color = 'W')\n","plt.ylabel('Count Density per Unit Area', fontsize = 15, color = 'W')\n","plt.plot(train['Plastic_Moving_Average_21'], color = 'darkgray')\n","plt.plot(valid['Plastic_Moving_Average_21'], color = 'skyblue')\n","plt.plot(valid['Predictions'], color = 'blue')\n","plt.legend(['Train', 'Actual', 'Predictions'], loc = 'upper right')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tcsgUBiHTuZk","colab_type":"code","colab":{}},"source":["model = Sequential()\n","model.add(LSTM(50, return_sequences=True, input_shape = (X_train_4.shape[1], 1)))\n","model.add(LSTM(50, return_sequences=False))\n","model.add(Dense(25))\n","model.add(Dense(1))\n","\n","model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n","\n","model.fit(X_train_4, y_train_4, batch_size = 3, epochs = 3)\n","\n","test_data_4 = scaled_data_4[training_data_length_4 - 30:, :]\n","\n","X_test_4 = []\n","y_test_4 = Dataset_4[training_data_length_4:, :]\n","\n","for i in range(30, len(test_data_4)) :\n","  X_test_4.append(test_data_4[i-30: i, 0])\n","\n","X_test_4 = np.array(X_test_4)\n","\n","X_test_4 = np.reshape(X_test_4, (X_test_4.shape[0], X_test_4.shape[1], 1))\n","\n","Predictions = model.predict(X_test_4)\n","Predictions = scaler.inverse_transform(Predictions)\n","\n","RMSE = np.sqrt(np.mean(Predictions - y_test_4)**2)\n","\n","RMSE"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5iUTUz1iUD_m","colab_type":"code","colab":{}},"source":["train = pollution_data_4_GroupByDate.filter(['Plastic_Moving_Average_36']).dropna(how='any')[:training_data_length_4]\n","valid = pollution_data_4_GroupByDate.filter(['Plastic_Moving_Average_36']).dropna(how='any')[training_data_length_4:]\n","valid ['Predictions'] = Predictions\n","\n","plt.figure(figsize=(16,8))\n","plt.title('Count Density', fontsize = 30)\n","plt.xlabel('Date', fontsize = 15, color = 'W')\n","plt.ylabel('Count Density per Unit Area', fontsize = 15, color = 'W')\n","plt.plot(train['Plastic_Moving_Average_36'], color = 'darkgray')\n","plt.plot(valid['Plastic_Moving_Average_36'], color = 'skyblue')\n","plt.plot(valid['Predictions'], color = 'blue')\n","plt.legend(['Train', 'Actual', 'Predictions'], loc = 'upper right')\n","plt.show()"],"execution_count":0,"outputs":[]}]}